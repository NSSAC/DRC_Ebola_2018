{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append('/Users/vsriniv/Documents/Research/Github/PatchSim')\n",
    "import patchsim as sim\n",
    "import matplotlib.ticker as plticker\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import hp, Trials\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_patchsim(x,forecast=False):\n",
    "    prep_param_file(x)\n",
    "    if forecast:\n",
    "        stages = 6\n",
    "    else:\n",
    "        stages = 5\n",
    "        \n",
    "    for s in range(stages):\n",
    "        cfg = sim.read_config('../data/patchsim/calib_cps/cfg_stage{}.txt'.format(s))\n",
    "        sim.run_disease_simulation(cfg,write_epi=True)\n",
    "\n",
    "    out_df = pd.DataFrame()\n",
    "    for s in range(stages):\n",
    "        temp_df = pd.read_csv('../outputs/sample{}.out'.format(s),delimiter=' ',header=None,index_col=0)       \n",
    "        if s==0:\n",
    "            out_df = temp_df.copy(deep=True)\n",
    "        else:\n",
    "            temp_df.columns = [x+len(out_df.columns) for x in temp_df.columns]\n",
    "            out_df = out_df.join(temp_df)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_param_file(x):\n",
    "    stages = 5\n",
    "    param_df = pd.DataFrame()\n",
    "    for s in range(stages):\n",
    "        temp = pd.read_csv('../data/patchsim/calib_cps/param_stage{}.txt'.format(s),delim_whitespace=True)\n",
    "        temp['stage'] = s\n",
    "        param_df = param_df.append(temp)\n",
    "\n",
    "    param_df['beta'] = param_df.apply(lambda row: get_param(row['id'],row['stage'],x),axis=1)\n",
    "    for s in range(stages):\n",
    "        param_df[param_df.stage==s][['id','beta','alpha','gamma']].to_csv('../data/patchsim/calib_cps/param_stage{}.txt'.format(s),sep=' ',index=None)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pd.read_csv('../data/Ebola_Updated_Apr9.csv', delimiter=',')\n",
    "gt['Date'] = gt.date.apply(lambda x: datetime.strptime(str(x),'%Y%m%d'))\n",
    "gt['Ob_Day'] = gt.Date.apply(lambda x : (x - datetime.strptime('20180805','%Y%m%d')).days)\n",
    "gt = gt[gt.Date>=datetime.strptime('20180805','%Y%m%d')] ## Starting on August 5th, the first non-NaN value\n",
    "\n",
    "key_hzs = gt[gt.Date==gt.Date.max()][['health_zone','total_c']].sort_values('total_c',ascending=False).head(7)['health_zone'].values\n",
    "key_hzs = sorted(list(set(key_hzs) - {'all'}))\n",
    "\n",
    "T = len(gt[gt.health_zone=='all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drc_error_func(out_df,w):\n",
    "    y_hat = out_df.sum().cumsum().values\n",
    "    y = gt[gt.health_zone=='all']['total_c'].values\n",
    "    print(len(y_hat),len(y))\n",
    "    diff = np.abs(y_hat-y)\n",
    "    disc_wt = [w**(len(diff)-1-x) for x in range(len(diff))] \n",
    "\n",
    "    return sum(disc_wt*diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hz_error_func(out_df,w):\n",
    "    calib_key_hzs = key_hzs\n",
    "    y_hat = out_df.loc[[k.upper() for k in calib_key_hzs]].cumsum(axis=1).values\n",
    "    y = gt.pivot(index='health_zone',columns='Ob_Day',values='total_c').loc[calib_key_hzs].fillna(0).values\n",
    "    diff = sum(np.abs(y_hat-y))\n",
    "    disc_wt = [w**(len(diff)-1-x) for x in range(len(diff))]\n",
    "    \n",
    "    return sum(disc_wt*diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_error_func(x):\n",
    "    w = 0.75\n",
    "    drc_wt = 0\n",
    "    hz_wt = 1\n",
    "    \n",
    "    out_df = run_patchsim(x)\n",
    "    \n",
    "    drc_err = drc_error_func(out_df,w)\n",
    "    hz_err = hz_error_func(out_df,w)\n",
    "    \n",
    "    pbar.update()\n",
    "    return drc_wt*drc_err + hz_wt*hz_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param(hz,stage,x):\n",
    "    ## x = [0.250, 0.210, 0.125, 0.070, 0.215, 0.11, 0.18, 0.215]  - Manual parameters\n",
    "    if (hz=='MABALAKO') & (stage==0): return x[0]       \n",
    "    if (hz=='BENI') & (stage<=1): return x[1]    \n",
    "    if (hz in ['BUTEMBO','KATWA']) & (stage==1): return x[2]\n",
    "    if (hz=='BENI') & (stage==2): return x[3]\n",
    "    if (hz=='KATWA') & (stage==2): return x[4]\n",
    "    if (hz in ['BUTEMBO','KATWA','MANDIMA']) & (stage==3): return x[5]\n",
    "    if (hz=='BENI') & (stage==4): return x[6]\n",
    "    if (hz in ['KATWA','MANDIMA','VUHOVI']) & (stage==4): return x[7]\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_labels = ['mab_s0','beni_s01','butkat_s1','beni_s2','kat_s2','bkm_s3','beni_s4','kmv_s4']\n",
    "x_space = [hp.uniform('0',0.24,0.26),\n",
    "           hp.uniform('1',0.20,0.22),\n",
    "           hp.uniform('2',0.11,0.14),\n",
    "           hp.uniform('3',0.06,0.08),\n",
    "           hp.uniform('4',0.20,0.22),\n",
    "           hp.uniform('5',0.1,0.12),\n",
    "           hp.uniform('6',0.16,0.19),\n",
    "           hp.uniform('7',0.2,0.22)\n",
    "          ]\n",
    "\n",
    "# x_space = [hp.uniform('0',0.25,0.25),\n",
    "#            hp.uniform('1',0.21,0.21),\n",
    "#            hp.uniform('2',0.125,0.125),\n",
    "#            hp.uniform('3',0.07,0.07),\n",
    "#            hp.uniform('4',0.21,0.21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "max_evals = 100\n",
    "pbar = tqdm(total=max_evals, desc=\"Calibration\")\n",
    "x_opt_dict = hyperopt.fmin(agg_error_func, space=x_space, algo=hyperopt.rand.suggest, max_evals=max_evals, trials=trials)  \n",
    "x_opt = [x_opt_dict[str(i)] for i in range(len(x_space))]\n",
    "particles_df = pd.DataFrame(dict(sorted({int(k):v for k,v in trials.vals.items()}.items())))\n",
    "particles_df.columns = column_labels\n",
    "particles_df['loss'] = trials.losses()\n",
    "pbar.close()\n",
    "\n",
    "print(x_opt)\n",
    "particles_df.to_csv('../outputs/cp_particles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimal parameter from Feb 28th run based on Feb 18th data\n",
    "# x_opt = [0.24189613655403158, 0.20772406549760183, 0.12970808099550318, 0.07981989143308324, 0.20435255948714667]\n",
    "\n",
    "# Optimal parameter from Feb 28th run based on Feb 26th data\n",
    "# x_opt = [0.244952079389403, 0.2090087781918788, 0.12680136060264208, 0.0737008978296486, 0.20346279800533526]\n",
    "\n",
    "# Optimal parameters from Apr 19th run based on Apr 9th data\n",
    "x_opt = [0.2599897740591754, 0.20795955479216033, 0.11668827288373881, 0.06318717639586165, 0.20088160521758575, 0.11065333548067946, 0.17111572153950488, 0.21893585329395385]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "f,axarr = plt.subplots(1,2,figsize=(24,8))\n",
    "\n",
    "forecast = False\n",
    "scenario = 'C'\n",
    "if forecast:\n",
    "    \n",
    "    if scenario=='A':  ## KATWA continue with same beta as stage 2, BUTEMBO goes back to parameter at stage 1.\n",
    "        temp = pd.read_csv('../data/patchsim/calib_cps/param_stage2.txt',delim_whitespace=True)\n",
    "        temp2 = pd.read_csv('../data/patchsim/calib_cps/param_stage1.txt',delim_whitespace=True)\n",
    "        temp = temp[temp['id']=='KATWA']\n",
    "        temp2 = temp2[temp2['id']=='BUTEMBO']\n",
    "        temp = pd.concat([temp,temp2])\n",
    "        temp.to_csv('../data/patchsim/calib_cps/param_stage3.txt',sep=' ',index=None)\n",
    "    \n",
    "    if scenario=='B':  ## KATWA continue with same beta as stage 2.\n",
    "        temp = pd.read_csv('../data/patchsim/calib_cps/param_stage2.txt',delim_whitespace=True)\n",
    "        temp = temp[temp['id']=='KATWA']\n",
    "        temp.to_csv('../data/patchsim/calib_cps/param_stage3.txt',sep=' ',index=None)\n",
    "\n",
    "    if scenario=='C':  ## KATWA reduces to BENI's beta at stage 2.\n",
    "        temp = pd.read_csv('../data/patchsim/calib_cps/param_stage2.txt',delim_whitespace=True)\n",
    "        val = temp[temp['id']=='BENI']['beta'].values[0]\n",
    "        temp['beta'] = temp.apply(lambda x: val if x['id']=='KATWA' else x['beta'],axis=1)\n",
    "        temp.to_csv('../data/patchsim/calib_cps/param_stage3.txt',sep=' ',index=None)\n",
    "        \n",
    "out_df = run_patchsim(x_opt,forecast)\n",
    "\n",
    "if forecast:\n",
    "    out_dict[scenario] = out_df\n",
    "    \n",
    "out_df.sum().cumsum().plot(label='Simulated',ax=axarr[0],color='k',style='--')\n",
    "axarr[0].plot(gt[gt.health_zone=='all'].total_c.values,label='Ground Truth',color='k')\n",
    "axarr[0].legend()\n",
    "\n",
    "out_df.loc[[k.upper() for k in key_hzs]].T.cumsum().plot(ax=axarr[1], style='--')\n",
    "axarr[1].legend().set_title('')\n",
    "axarr[1].set_prop_cycle(None)\n",
    "for h in key_hzs:\n",
    "    gt[gt.health_zone==h.capitalize()].reset_index().plot(y='total_c',ax=axarr[1],legend=None)\n",
    "    \n",
    "cp_timings = [20,100,197]    \n",
    "for t in cp_timings[:-1]:\n",
    "    axarr[0].axvline(t,color='#dbdbdb')\n",
    "    axarr[1].axvline(t,color='#dbdbdb')\n",
    "    \n",
    "loc = plticker.MultipleLocator(base=20) \n",
    "axarr[0].xaxis.set_major_locator(loc)\n",
    "axarr[1].xaxis.set_major_locator(loc)\n",
    "\n",
    "axarr[0].set_xlabel('Days',fontsize=12)\n",
    "axarr[1].set_xlabel('Days',fontsize=12)\n",
    "\n",
    "axarr[0].set_ylabel('Confirmed cases',fontsize=12)\n",
    "axarr[1].set_ylabel('Confirmed cases',fontsize=12)\n",
    "\n",
    "if forecast:\n",
    "    \n",
    "    axarr[0].axvspan(T,T+33,color='#dbdbdb',alpha=0.3)\n",
    "    axarr[1].axvspan(T,T+33,color='#dbdbdb',alpha=0.3)\n",
    "    \n",
    "    #plt.suptitle('Forecast Scenario {}'.format(scenario),fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../plots/forecast_scenario_{}.png'.format(scenario),dpi=100)\n",
    "else:\n",
    "    #plt.suptitle('Model calibration',fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../plots/model_calibration.png',dpi=100)\n",
    "    \n",
    "\n",
    "if forecast:\n",
    "    out_df.index = out_df.index.str.replace('_',' ')\n",
    "    out_wk = out_df.groupby((out_df.columns - 1)// 7, axis=1).sum()\n",
    "    wk_range = out_wk.columns[:-1]\n",
    "    out_wk = out_wk[wk_range]\n",
    "\n",
    "    out_wk['Last5'] = out_wk[wk_range[-5:]].sum(axis=1)\n",
    "    temp_df = out_wk.sort_values('Last5',ascending=False)[['Last5']]\n",
    "    temp_df['risk_index'] = temp_df.Last5/temp_df.Last5.sum()\n",
    "    temp_df[['risk_index']].head(10).to_html('../plots/risk_table_{}.html'.format(scenario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_a = out_dict['A'].sum().cumsum().values\n",
    "curve_b = out_dict['B'].sum().cumsum().values\n",
    "curve_c = out_dict['C'].sum().cumsum().values\n",
    "curve_gt = gt[gt.health_zone=='all']['total_c'].values\n",
    "\n",
    "tot_a = curve_a[-1]\n",
    "tot_b = curve_b[-1]\n",
    "tot_c = curve_c[-1]\n",
    "tot_gt = curve_gt[-1]\n",
    "\n",
    "print('Total confirmed cases in ground truth: {}'.format(int(tot_gt)))\n",
    "print('Total cases in each scenario: A - {}, B - {}, C - {}'.format(int(tot_a),int(tot_b),int(tot_c)))\n",
    "\n",
    "print('% increase in Scenario A in comparison to ground truth: {}%'.format(round((tot_a-tot_gt)*100/tot_gt,2)))\n",
    "print('% increase in Scenario B in comparison to ground truth: {}%'.format(round((tot_b-tot_gt)*100/tot_gt,2)))\n",
    "print('% increase in Scenario C in comparison to ground truth: {}%'.format(round((tot_c-tot_gt)*100/tot_gt,2)))\n",
    "\n",
    "print('% increase in Scenario A in comparison to scenario B: {}%'.format(round((tot_a-tot_b)*100/tot_b,2)))\n",
    "print('% increase in Scenario A in comparison to scenario C: {}%'.format(round((tot_a-tot_c)*100/tot_b,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in out_dict.keys():\n",
    "    out_dict[k].to_csv('../outputs/forecast_2019feb28_sc{}.csv'.format(k))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
